{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haar cascading\n",
    "\n",
    "\n",
    "Before we jump into creating stable face detection, let's take a moment to understand a Haar cascade classifiers, a form of future-based machine learning. It works by first training a classifier with set of labeled positive and negatives. Or in other words, indicating to the classifier that these are sets of images that have faces and these are sets of images that don't have faces. This classifier then learns from the set by understanding and extracting features from all the images. For example, it may naturally learn that the region of the eye is as typically darker than the region of the cheeks below and may use that as one of its thousands of indicators that help understand whether not a particular region of interest, or ROI, is a face or not. After the training is completed, and a classifier is defined, we use the classifier in a cascaded manner to run through all the feature checks. This cascade method works like a waterfall, where you apply the fastest and most general checks first in order to quickly rule out areas that are definitely not matching a face without spending too much computational time. As it becomes more refined and goes through more classifiers, it gets more and more sure that the region of interest is actually a face. If it gets through all the cascaded classifiers, it is then marked as a valid face and outputs the bounding blocks. When we run the face detection algorithm and open CV, using the training data, we essentially leverage the already trained information into a cascade classifier which would then output the set of found faces and the regions of interests. Note however, is not always perfect. And is possible that there will still be false positives and false negatives. Since your training data is rarely ever exactly the same as the applied data, you always are at risk at false negatives or positives. But there are parameters to tweak the classifier to make it more accurate for the particular situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face detection\n",
    "\n",
    "\n",
    "Now, let's take a look at the specific use case of detecting faces in image using the pre-learn hard classifier. Again, note that detection is not the same thing as recognition; we are only detecting if and where faces are located in an image. For this, we're going to use the pre-included hard classifier found in the chapter four of module five folder. You can see this is the haarcascade_frontalface_default.xml file. Now, let's jump into our scripting window where we'll load up the chapter four module five python file. Note that we've already loaded in our image; faces.jpeg and fill color as indicated by the value of one. Next, for the actual classifier, we want to turn this into gray scale. For this, we can type gray equals cv2.cvtColor and then pass img,cv2.COLOR_BGR2GRAY. Next, let's actually define the path for our xml file by typing path equals \"haarcascade_frontalface_default.xml\". Next, let's actually create our cascade object. To do this, we'll type face_cascade equals cv2.CascadeClassifier and then we will pass in our path. What this does is actually it loads in the xml and initializes our cascades of function and classifiers. The end python object is what we are using to create our face detection. It contains all the functions and many classifiers as well as the function to pass in an image to detect faces. Now, let's actually run that function by typing faces equals face_cascade which is the object we just created .detectMultiScale and then we'll pass in gray, and then we'll pass in a few parameters. The first one will be scaleFactor equals 1.05 and noting that this is a compensating factor for only wanting faces close to the camera; ,minNeighbors equals five knowing that this factor sets a number of nearby object detections required before it's considered a face; ,minSize equals (40,40). Then, in this last factor, is the actual minimum size of a face to count before it's detected and in your last parenthesis we note that the result of this operation is creating a list that contains all the bounding boxes for detected faces. If there are no faces found in an image, the length of a list would be set as zero. To check this, we can type print and then len and then pass in our faces list ending our parenthesis. Now, let's actually draw these bounding boxes onto original image. Type for; in parenthesis x, y, w, h indicating that each face object in our list has an x, y within height variable in faces: and then pressing Enter, we'll draw using cv2.rectangle and then we'll pass our original image; comma and then we'll pass in parenthesis our x, y for the top-left corner followed by the next point x+w,y+h for the bottom right-hand corner; comma, we'll pas in a color such as zero , 255, zero and then, finally, we'll pass in a value of two for the line thickness. Next, let's show our image using cv2.imshow(\"Image\",img) and then you use cv2.waitKey(0) and cv2.destroyAllWindows. At this point, I'm going to press Save and then return to my command line prompt typing out python3 04_05.py; I'll press Enter and then we can see the result of all of our faces being detected. Notice, for example, that are actually overdetected meaning there are a few false positives up in the top left-hand corner. If I press Escape and return to my console and modify my scale factor, for example, to be a value of 1.10 and then press Save. Rerunning my script, I've noted that there's one fewer false positive, but then I actually have false negatives. There are two faces that are now no longer even being detected. This is a good reminder that we are working with trained data sets meaning the classifiers will not necessarily be perfect and they may not be suited for all situations and all images. You can typically (mumbles) the classifier used to improve your results or you can train your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"faces.jpeg\",1)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(path)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.10, minNeighbors=5, minSize=(40,40))\n",
    "print(len(faces))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "\tcv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "cv2.imshow(\"Image\",img)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
