{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution: Eye detection\n",
    "\n",
    "\n",
    "* Now let's take a look at the solution to this challenge. As a reminder, we are tasked with drawing circles around all the eyes in an image. To do this, we're going to use the Haar Cascade Method using the provided haarcascade_eye.xml file. Similar to the face train file, this is pre-trained data around detecting eyes in images. Additionally we're going to try and reduce the number of false positives and false negatives as much as possible. Now let's take a look at the chapter four module six pre-included Python file. In here, we see that we already have our faces loaded in and have read in in full color. Next let's convert to gray using gray = cv2.cvtColor then passing in image, then cv2.COLOR_BGR2GRAY. Then we'll set our path to be our xml file, typing path = haarcascade_eye.xml. Next we'll create our eye_cascade object = cv2.Cascade, capitalized, Classifier, also capitalized, then pass in our path. Then we're going to create our eyes output. Eyes = eye_cascade.detectMultiScale where the M and S are capitalized. Then we will pass in our gray image followed by scaleFactor=1.02,minNeighbors=20, and then minSize=10,10. This will then output the results of all matching eyes. You should know that this is the exact same format as we used for the face detection. The only difference is this time we're using different training data. Thus we have a resulting list of bounding boxes of all eyes found in the image. Printing len of eyes will show in the console the number of eyes detected and then we can loop over all these objects to actually draw a circle around them. To do this, we will type for x, y, w, h in eyes and then we need to draw our circle. Now part of the twist of this challenge was that we are provided all the information to draw a rectangle, not a circle and so we must do the conversion ourself. The first thing we want to do is calculate the center of our new circle. To do this, we can do the x1 - x2 and y1 - y2 approach for calculating the new centers. In this case, we can type xc = and then parentheses, we'll use the first x followed by the second x value which is x+w divided by two and in the same way, we can type (yc = y + y+h)/2. Next let's define the radius. This can be accomplished by using either the width or the height divided by two, typing out radius = w/2. Now we can draw our circle cv2.circle, open parentheses we'll pass in our full color image, img and then we need to pass in our new center. For this, we need to actually cast our xc and yc values into integer values. To do this, we'll type int and then we'll type xc, closed parentheses and then we'll type int yc, closed parentheses, closed parentheses and then we need to pass in our radius, which once again, also needs to be casted into an integer, typing int, radius, next we define the color of our circles by typing 255, 0, 0, for blue and then we can specify a width of the circles of two. Now we're ready to show our image using cv2.imshow, eyes,img. Now let's finish off by typing cv2.waitKey(0) cv2.destroy all windows. Pressing save, I'll now return to my command line prompt. I'll make sure I'm in the right location and that my files exist and then I will type python3 04_06.py. Now we can see the result of us drawing the circles around the eyes. It is certainly not perfect, but we can see it is working successfully in a number of cases. Pointing them out briefly, for example the top left hand corner, we can see that there's a false positive as a circle is drawn around a hairline. Conversely if you look at the gentlemen on the far right down one row, you can see that only one of his eyes is being selected. The other eye is a false negative, as we missed drawing it. A lot of time can be spent adjusting the parameters. We know that these have been modified from what we used in the face detection and I admit you could probably come up with better parameters even yourself. Note as it was true with the face detection, it all comes down to the fact that this is machine learned data, in other words your results are only as good as your training data and if the training images were vastly different from the images we're using now, you may end up being required to create your own classifier and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"faces.jpeg\",1)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "path = \"haarcascade_eye.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "eye_cascade = cv2.CascadeClassifier(path)\n",
    "\n",
    "eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.02,minNeighbors=20,minSize=(10,10))\n",
    "print(len(eyes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, w, h) in eyes:\n",
    "\txc = (x + x+w)/2\n",
    "\tyc = (y + y+h)/2\n",
    "\tradius = w/2\n",
    "\tcv2.circle(img, (int(xc),int(yc)), int(radius), (255,0,0), 2)\n",
    "cv2.imshow(\"Eyes\",img)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sillians\\\\Downloads\\\\Practical data science works\\\\Ex_Files_OpenCV_Python_Dev\\\\Ex_Files_OpenCV_Python_Dev\\\\Exercise Files\\\\Ch04\\\\04_07 Solution'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
